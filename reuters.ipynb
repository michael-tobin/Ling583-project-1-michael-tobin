{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "numerical-czech",
   "metadata": {},
   "source": [
    "# PROJECT 1: Categorizing news articles\n",
    "\n",
    "### Your task\n",
    "* Given a bunch of Reuters news service articles, develop a set of labels for categorizing them\n",
    "* Labels should be a single word or short phrase. Some articles might fit more than one label, and some might not fit any.\n",
    "* Aim for about 10–15 labels, give or take\n",
    "* Use methods from labs so far (keyword analysis, terminology extraction, topic models)\n",
    "* No specific ‘correct’ answer; the process you use to develop the list is more important than the solution.\n",
    "\n",
    "### Deliverables\n",
    "* List of labels\n",
    "* For each label, the number of articles from the dataset that fit that label\n",
    "* The number of articles that don't fit any of the labels (ideally this won't be a big number)\n",
    "* Annotated notebook showing your process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ordered-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cytoolz import *\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "another-segment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50085"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data from the S3 bucket\n",
    "df = pd.read_parquet('s3://ling583/project1.parquet', storage_options={'anon':True})\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "overhead-tamil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f5f8db6f3747c38459cde825783624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "49844"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove non-english articles\n",
    "import pycld2\n",
    "\n",
    "def guess_lang(text):\n",
    "    try:\n",
    "        reliable, _, langs = pycld2.detect(\n",
    "            text, isPlainText=True, hintLanguage='en')\n",
    "        if reliable:\n",
    "            return langs[0][0]\n",
    "    except pycld2.error as e:\n",
    "        pass\n",
    "    return np.NaN\n",
    "\n",
    "\n",
    "df['lang'] = df['text'].progress_apply(guess_lang)\n",
    "df = df[df['lang'] == 'ENGLISH'].reset_index(drop=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "reasonable-nerve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>byline</th>\n",
       "      <th>dateline</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planet Hollywood launches credit card.</td>\n",
       "      <td>If dining at Planet Hollywood made you feel li...</td>\n",
       "      <td>None</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>1996-08-20</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>[if, dining, at, planet, hollywood, made, you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sprint to offer consumer Internet access service.</td>\n",
       "      <td>Sprint Corp. Tuesday announced plans to offer ...</td>\n",
       "      <td>Susan Nadeau</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>1996-08-20</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>[sprint, corp., tuesday, announced, plans, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chains may raise prices after minimum wage hike.</td>\n",
       "      <td>The higher minimum wage signed into law Tuesda...</td>\n",
       "      <td>Patricia Commins</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>1996-08-20</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>[the, higher, minimum, wage, signed, into, law...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sprint to offer consumer Internet access service.</td>\n",
       "      <td>Sprint Corp. Tuesday announced plans to offer ...</td>\n",
       "      <td>None</td>\n",
       "      <td>KANSAS CITY, Mo.</td>\n",
       "      <td>1996-08-20</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>[sprint, corp., tuesday, announced, plans, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sprint to offer consumer Internet access service.</td>\n",
       "      <td>Sprint Corp. Tuesday announced plans to offer ...</td>\n",
       "      <td>None</td>\n",
       "      <td>KANSAS CITY, Mo.</td>\n",
       "      <td>1996-08-20</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>[sprint, corp., tuesday, announced, plans, to,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0             Planet Hollywood launches credit card.   \n",
       "1  Sprint to offer consumer Internet access service.   \n",
       "2   Chains may raise prices after minimum wage hike.   \n",
       "3  Sprint to offer consumer Internet access service.   \n",
       "4  Sprint to offer consumer Internet access service.   \n",
       "\n",
       "                                                text            byline  \\\n",
       "0  If dining at Planet Hollywood made you feel li...              None   \n",
       "1  Sprint Corp. Tuesday announced plans to offer ...      Susan Nadeau   \n",
       "2  The higher minimum wage signed into law Tuesda...  Patricia Commins   \n",
       "3  Sprint Corp. Tuesday announced plans to offer ...              None   \n",
       "4  Sprint Corp. Tuesday announced plans to offer ...              None   \n",
       "\n",
       "           dateline        date     lang  \\\n",
       "0       LOS ANGELES  1996-08-20  ENGLISH   \n",
       "1           CHICAGO  1996-08-20  ENGLISH   \n",
       "2           CHICAGO  1996-08-20  ENGLISH   \n",
       "3  KANSAS CITY, Mo.  1996-08-20  ENGLISH   \n",
       "4  KANSAS CITY, Mo.  1996-08-20  ENGLISH   \n",
       "\n",
       "                                              tokens  \n",
       "0  [if, dining, at, planet, hollywood, made, you,...  \n",
       "1  [sprint, corp., tuesday, announced, plans, to,...  \n",
       "2  [the, higher, minimum, wage, signed, into, law...  \n",
       "3  [sprint, corp., tuesday, announced, plans, to,...  \n",
       "4  [sprint, corp., tuesday, announced, plans, to,...  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-compensation",
   "metadata": {},
   "source": [
    "## Find Multiple-Word-Expressions (MWE) to help with the labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "virgin-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', exclude=[\n",
    "                 'parser', 'ner', 'lemmatizer', 'attribute_ruler'])\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('Term', [[{'TAG': {'IN': ['JJ', 'NN', 'NNP']}},\n",
    "                      {'TAG': {'IN': ['JJ', 'NN', 'IN',\n",
    "                                      'HYPH', 'NNP']}, 'OP': '*'},\n",
    "                      {'TAG': {'IN': ['NN', 'NNP']}}]])\n",
    "\n",
    "\n",
    "def get_candidates(text):\n",
    "    doc = nlp(text)\n",
    "    spans = matcher(doc, as_spans=True)\n",
    "    return [tuple(tok.norm_ for tok in span) for span in spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "specified-grounds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:41587</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.62 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:41587' processes=4 threads=4, memory=16.62 GB>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://127.0.0.1:41587\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "guilty-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "\n",
    "texts = dd.from_pandas(df['text'].sample(\n",
    "    len(df), random_state=19), npartitions=50).to_bag()\n",
    "\n",
    "graph = texts.map(get_candidates).flatten().frequencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pregnant-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.35 s, sys: 781 ms, total: 6.14 s\n",
      "Wall time: 3min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "candidates = graph.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "selected-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "\n",
    "def get_subterms(term):\n",
    "    k = len(term)\n",
    "    for m in range(k-1, 1, -1):\n",
    "        yield from ngrams(term, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "becoming-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from math import log2\n",
    "\n",
    "freqs = defaultdict(Counter)\n",
    "for c, f in candidates:\n",
    "    freqs[len(c)][c] += f\n",
    "\n",
    "\n",
    "def c_value(F, theta):\n",
    "\n",
    "    termhood = Counter()\n",
    "    longer = defaultdict(list)\n",
    "\n",
    "    for k in sorted(F, reverse=True):\n",
    "        for term in F[k]:\n",
    "            if term in longer:\n",
    "                discount = sum(longer[term]) / len(longer[term])\n",
    "            else:\n",
    "                discount = 0\n",
    "            c = log2(k) * (F[k][term] - discount)\n",
    "            if c > theta:\n",
    "                termhood[term] = c\n",
    "                for subterm in get_subterms(term):\n",
    "                    if subterm in F[len(subterm)]:\n",
    "                        longer[subterm].append(F[k][term])\n",
    "    return termhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "macro-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = c_value(freqs, theta=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "animated-advertiser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7157.00  7494 new york\n",
      " 6833.00  7311 hong kong\n",
      " 5999.67  6325 last year\n",
      " 5095.36  5879 air cargo\n",
      " 4348.00  4348 united states\n",
      " 3760.17  2545 long - distance\n",
      " 3327.00  3327 percent stake\n",
      " 3226.00  3226 general cargo\n",
      " 3166.76  1998 london newsroom +44\n",
      " 2796.00  1830 air cargo newsroom tel+44\n",
      " 2539.50  3158 chief executive\n",
      " 2477.00  2577 co ltd\n",
      " 2471.00  2694 net income\n",
      " 2466.00  2466 last week\n",
      " 2464.00  2464 joint venture\n",
      " 2393.61  2268 air cargo newsroom\n",
      " 2383.00  2793 stock exchange\n",
      " 2299.78  2215 cargo newsroom tel+44\n",
      " 2228.46  1406 long - term\n",
      " 2217.00  2217 first quarter\n"
     ]
    }
   ],
   "source": [
    "for t, c in terms.most_common(20):\n",
    "    print(f'{c:8.2f} {freqs[len(t)][t]:5d} {\" \".join(t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cognitive-uzbekistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  204.00   204 oil \t\t \n",
      "  204.00   204 industrial action\n",
      "  204.00   204 plc     \n",
      "  203.00   203 group inc.\n",
      "  202.88   128 percent last year\n",
      "  202.88   128 john f. kennedy\n",
      "  202.88   128 browns group plc\n",
      "  202.00   101 nz it \t     london\n",
      "  202.00   101 year - ago quarter\n",
      "  202.00   101 sao paulo newsroom +55\n",
      "  202.00   326 trans world\n",
      "  202.00   202 vice chairman\n",
      "  202.00   202 ashok leyland\n",
      "  202.00   202 cargo official\n",
      "  201.29   127 long - range\n",
      "  201.29   127 countrywide - pp\n",
      "  201.00   201 strategic alliance\n",
      "  201.00   481 paulo newsroom\n",
      "  201.00   201 conversion rate\n",
      "  201.00   201 german airline\n"
     ]
    }
   ],
   "source": [
    "for t, c in tail(20, terms.most_common()):\n",
    "    print(f'{c:8.2f} {freqs[len(t)][t]:5d} {\" \".join(t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "capable-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the terms for later use\n",
    "with open('article-terms.txt', 'w') as f:\n",
    "    for t in terms:\n",
    "        print(' '.join(t), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "unsigned-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the terms\n",
    "from tokenizer import MWETokenizer\n",
    "\n",
    "tokenizer = MWETokenizer(open('article-terms.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "super-disclaimer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f596aa171984ef98644711276718f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49844 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add a new column to the dataframe, 'tokens' that is the tokenized version of the 'text' column\n",
    "df['tokens'] = pd.Series(df['text'].progress_apply(tokenizer.tokenize))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-familiar",
   "metadata": {},
   "source": [
    "# If you have article-topics.bin, skip to next bold comment, otherwise run the below code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-milwaukee",
   "metadata": {},
   "source": [
    "### This is just to save time on subsequent runs for refining processes\n",
    "Running these blocks takes 13 minutes on my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "amazing-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomotopy as tp\n",
    "import time\n",
    "k = 200                  # number of topics\n",
    "min_df = 20              # minimum number of articles that a term has to occur in to be included in the model\n",
    "rm_top = 75              # number of most frequent terms to remove from the model\n",
    "tw = tp.TermWeight.ONE   # term weighting strategy\n",
    "alpha = 0.1              # priors for document-topic and topic-word distributions\n",
    "eta = 0.01               # priors for document-topic and topic-word distributions\n",
    "tol = 1e-3               # convergence tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "developmental-commission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 LL = -8.1788\n",
      "   50 LL = -7.9913\n",
      "  100 LL = -7.9270\n",
      "  150 LL = -7.8978\n",
      "  200 LL = -7.8778\n",
      "  250 LL = -7.8658\n",
      "  300 LL = -7.8587\n",
      "  350 LL = -7.8515\n",
      "  400 LL = -7.8477\n",
      "  450 LL = -7.8419\n",
      "  500 LL = -7.8384\n",
      "  550 LL = -7.8353\n",
      "  600 LL = -7.8329\n",
      "  650 LL = -7.8314\n",
      "  700 LL = -7.8314\n",
      "Done!\n",
      "CPU times: user 37min 2s, sys: 19.8 s, total: 37min 22s\n",
      "Wall time: 12min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mdl = tp.LDAModel(k=k, min_df=min_df, rm_top=rm_top, tw=tw, alpha=alpha, eta=eta)\n",
    "\n",
    "for doc in df['tokens']:\n",
    "    if doc:\n",
    "        mdl.add_doc(doc)\n",
    "\n",
    "last = np.NINF\n",
    "for i in range(0, 5000, 50):\n",
    "    mdl.train(50)\n",
    "    ll = mdl.ll_per_word\n",
    "    print(f'{i:5d} LL = {ll:7.4f}', flush=True)\n",
    "    if ll - last < tol:\n",
    "        break\n",
    "    else:\n",
    "        last = ll\n",
    "\n",
    "print(f'Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the results of the above processes\n",
    "# NOTE: This is 200 lines long\n",
    "for k in range(mdl.k):\n",
    "    print(f'{k:3d} ', ', '.join(s for s,_ in mdl.get_topic_words(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "racial-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.save('article-topics.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-wayne",
   "metadata": {},
   "source": [
    "# If you have article-topics.bin, skip the above 3 blocks and run the code below.\n",
    "### If you had to run the above code, there is no need to run the next line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = tp.LDAModel.load('article-topics.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-infrastructure",
   "metadata": {},
   "source": [
    "# Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "sized-dance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>byline</th>\n",
       "      <th>dateline</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planet Hollywood launches credit card.</td>\n",
       "      <td>If dining at Planet Hollywood made you feel li...</td>\n",
       "      <td>None</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>1996-08-20</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>[if, dining, at, planet, hollywood, made, you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sprint to offer consumer Internet access service.</td>\n",
       "      <td>Sprint Corp. Tuesday announced plans to offer ...</td>\n",
       "      <td>Susan Nadeau</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>1996-08-20</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>[sprint, corp., tuesday, announced, plans, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chains may raise prices after minimum wage hike.</td>\n",
       "      <td>The higher minimum wage signed into law Tuesda...</td>\n",
       "      <td>Patricia Commins</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>1996-08-20</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>[the, higher, minimum, wage, signed, into, law...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sprint to offer consumer Internet access service.</td>\n",
       "      <td>Sprint Corp. Tuesday announced plans to offer ...</td>\n",
       "      <td>None</td>\n",
       "      <td>KANSAS CITY, Mo.</td>\n",
       "      <td>1996-08-20</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>[sprint, corp., tuesday, announced, plans, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sprint to offer consumer Internet access service.</td>\n",
       "      <td>Sprint Corp. Tuesday announced plans to offer ...</td>\n",
       "      <td>None</td>\n",
       "      <td>KANSAS CITY, Mo.</td>\n",
       "      <td>1996-08-20</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>[sprint, corp., tuesday, announced, plans, to,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0             Planet Hollywood launches credit card.   \n",
       "1  Sprint to offer consumer Internet access service.   \n",
       "2   Chains may raise prices after minimum wage hike.   \n",
       "3  Sprint to offer consumer Internet access service.   \n",
       "4  Sprint to offer consumer Internet access service.   \n",
       "\n",
       "                                                text            byline  \\\n",
       "0  If dining at Planet Hollywood made you feel li...              None   \n",
       "1  Sprint Corp. Tuesday announced plans to offer ...      Susan Nadeau   \n",
       "2  The higher minimum wage signed into law Tuesda...  Patricia Commins   \n",
       "3  Sprint Corp. Tuesday announced plans to offer ...              None   \n",
       "4  Sprint Corp. Tuesday announced plans to offer ...              None   \n",
       "\n",
       "           dateline        date     lang  \\\n",
       "0       LOS ANGELES  1996-08-20  ENGLISH   \n",
       "1           CHICAGO  1996-08-20  ENGLISH   \n",
       "2           CHICAGO  1996-08-20  ENGLISH   \n",
       "3  KANSAS CITY, Mo.  1996-08-20  ENGLISH   \n",
       "4  KANSAS CITY, Mo.  1996-08-20  ENGLISH   \n",
       "\n",
       "                                              tokens  \n",
       "0  [if, dining, at, planet, hollywood, made, you,...  \n",
       "1  [sprint, corp., tuesday, announced, plans, to,...  \n",
       "2  [the, higher, minimum, wage, signed, into, law...  \n",
       "3  [sprint, corp., tuesday, announced, plans, to,...  \n",
       "4  [sprint, corp., tuesday, announced, plans, to,...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-kennedy",
   "metadata": {},
   "source": [
    "## Create a dataframe of the topics for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fewer-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of the tokens that make up each topic, only has the tokens column for now\n",
    "topics = pd.DataFrame({'tokens': [' '.join(map(first, mdl.get_topic_words(k))) for k in range(mdl.k)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "explicit-concept",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pesos philippine philippines corp pldt inc fax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stet italian italy lire telecom_italia state i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>miami county american latin_america florida ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>top survey according average fund among study ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>customers phone service calls call telephone n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens\n",
       "0  pesos philippine philippines corp pldt inc fax...\n",
       "1  stet italian italy lire telecom_italia state i...\n",
       "2  miami county american latin_america florida ca...\n",
       "3  top survey according average fund among study ...\n",
       "4  customers phone service calls call telephone n..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-individual",
   "metadata": {},
   "source": [
    "### Create and manually update the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "interested-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the dataframe to a CSV for further manipulation\n",
    "topics.to_csv('topics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-facing",
   "metadata": {},
   "source": [
    "#### Edit the resulting CS, manually add a column \"label\" and manually label as many rows as possible. Labels are determined by the user, then saved.\n",
    "Aim for 10-15 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "abstract-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After adding labels, read the CSV back into the dataframe\n",
    "topics = pd.read_csv('topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "coupled-calcium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pesos philippine philippines corp pldt inc fax...</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stet italian italy lire telecom_italia state i...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>miami county american latin_america florida ca...</td>\n",
       "      <td>america</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>top survey according average fund among study ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>customers phone service calls call telephone n...</td>\n",
       "      <td>telecom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tax state city bill airport authority federal ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>newspaper comment report reported declined spo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>europe asia countries world international regi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>shareholders meeting board shareholder vote di...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>securities 9 1995 average pesos bln forecast c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tokens     label\n",
       "0    pesos philippine philippines corp pldt inc fax...      asia\n",
       "1    stet italian italy lire telecom_italia state i...   telecom\n",
       "2    miami county american latin_america florida ca...   america\n",
       "3    top survey according average fund among study ...       NaN\n",
       "4    customers phone service calls call telephone n...   telecom\n",
       "..                                                 ...       ...\n",
       "195  tax state city bill airport authority federal ...       NaN\n",
       "196  newspaper comment report reported declined spo...       NaN\n",
       "197  europe asia countries world international regi...       NaN\n",
       "198  shareholders meeting board shareholder vote di...  business\n",
       "199  securities 9 1995 average pesos bln forecast c...       NaN\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataframe now has 2 columns, the original 'tokens' and the added 'label'\n",
    "# Empty labels are returned as NaN, we will fix this next.\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "literary-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the labels, removing duplicates and empty values\n",
    "list_of_labels = list(set(topics['label'].dropna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-crown",
   "metadata": {},
   "source": [
    "### This is just a review of what we are working with so far, using 1 article as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "devoted-gardening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the original text of the article:\n",
      "\n",
      "French Riviera train conductors ended a 36-hour strike on Tuesday against growing crime which has badly disrupted traffic at the peak summer holiday period. A trade union spokesman said the management of state railway company SNCF had responded to the protest by promising to increase staff and equip conductors with portable telephones to tighten security on routes regarded as dangerous. Unionists say train conductors in southeast France are increasingly at risk from fare dodgers, pickpockets and thugs. The strike forced SNCF to cancel five long distance trains between Marseille and Nice and 75 percent of regional traffic on Monday. High-speed trains ran normally.\n"
     ]
    }
   ],
   "source": [
    "print('Here is the original text of the article:\\n')\n",
    "print(df['text'].iloc[166])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "italian-classic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Here is the topics structure for that same article:\n",
      "\n",
      "<tomotopy.Document with words=\"french riviera train conductors ended a 36 hour_strike on tuesday against growing crime which has badly disrupted traffic at the peak summer holiday period a trade_union spokesman said the management of state railway company sncf had responded to the protest by promising to increase staff and equip conductors with portable telephones to tighten security on routes regarded as dangerous unionists say train conductors in southeast france are increasingly at risk from fare dodgers pickpockets and thugs the strike forced sncf to cancel five long_distance trains between marseille and nice and 75 percent of regional traffic on monday high-speed trains ran normally\">\n"
     ]
    }
   ],
   "source": [
    "print('\\n Here is the topics structure for that same article:\\n')\n",
    "print(mdl.docs[166])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "aerial-night",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is the list of topics and their pairs that correlates to the rows in 'topics':\n",
      "\n",
      "[(190, 0.34260496497154236), (175, 0.20863720774650574), (39, 0.10455581545829773), (48, 0.07458535581827164), (27, 0.05965302884578705), (52, 0.04533909633755684), (197, 0.030088625848293304), (125, 0.029965976253151894), (24, 0.029858462512493134), (49, 0.015399456024169922)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nHere is the list of topics and their pairs that correlates to the rows in 'topics':\\n\")\n",
    "print(mdl.docs[166].get_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "variable-chance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is that same list, filtered to exclude any topic with a weight less than 0.01\n",
      "\n",
      "[190, 175, 39, 48, 27, 52, 197, 125, 24, 49]\n"
     ]
    }
   ],
   "source": [
    "print('\\nHere is that same list, filtered to exclude any topic with a weight less than 0.01\\n')\n",
    "print([t for t,w in mdl.docs[166].get_topics() if w>0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "usual-lighter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Followed by the label that corresponds to those topics:\n",
      "Note that some are nan, which means there is no label associated with that topic.\n",
      "\n",
      "['politics', nan, nan, nan, nan, nan, nan, 'telecom', 'money', 'money']\n"
     ]
    }
   ],
   "source": [
    "print('\\nFollowed by the label that corresponds to those topics:\\nNote that some are nan, which means there is no label associated with that topic.\\n')\n",
    "print([topics['label'].loc[t] for t,w in mdl.docs[166].get_topics() if w>0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "official-plant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finally, here is that same list of labels for topics after having nan values and duplicates removed:\n",
      "\n",
      "{'telecom', 'money', 'politics'}\n"
     ]
    }
   ],
   "source": [
    "print('\\nFinally, here is that same list of labels for topics after having nan values and duplicates removed:\\n')\n",
    "print(set(filter(pd.notna, [topics['label'].loc[t] for t,w in mdl.docs[166].get_topics() if w>0.01])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-shell",
   "metadata": {},
   "source": [
    "## Process the labels for each article in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "leading-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(index):\n",
    "    return list(set(filter(pd.notna, [topics['label'].loc[t] for t,w in mdl.docs[index].get_topics() if w>0.01])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "random-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(df):\n",
    "    from collections import Counter\n",
    "    label_list = []\n",
    "    no_label=0\n",
    "    \n",
    "    # get the labels for each element\n",
    "    for index, row in df.iterrows():\n",
    "        labels = get_labels(index)\n",
    "        if len(labels)==0:\n",
    "            no_label += 1\n",
    "        else:\n",
    "            label_list.extend(labels)\n",
    "    \n",
    "    # Create a dictionary of the counts for each label\n",
    "    label_dist = dict(Counter(label_list))\n",
    "    \n",
    "    # Add in the count of articles with no label\n",
    "    label_dist['no label']=no_label\n",
    "    return label_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "temporal-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_frequencies = get_counts(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-custom",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "* List of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "respiratory-adult",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business', 'australia', 'europe', 'shipping', 'telecom', 'oil', 'technology', 'airline', 'america', 'asia', 'money', 'politics']\n"
     ]
    }
   ],
   "source": [
    "# This is just a list of the labels that I added in the 'manually update .csv file' section\n",
    "print(list_of_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-fifth",
   "metadata": {},
   "source": [
    "* For each label, the number of articles from the dataset that fit that label\n",
    "* The number of articles that don't fit any of the labels (ideally this won't be a big number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "permanent-dress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': 21839,\n",
       " 'telecom': 15000,\n",
       " 'money': 28973,\n",
       " 'airline': 20443,\n",
       " 'politics': 5564,\n",
       " 'asia': 6142,\n",
       " 'technology': 4258,\n",
       " 'shipping': 9107,\n",
       " 'europe': 1264,\n",
       " 'australia': 1337,\n",
       " 'america': 808,\n",
       " 'oil': 1319,\n",
       " 'no label': 3659}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many articles are classified using each label\n",
    "# Articles may have zero or more labels.\n",
    "# If an article has more than one label, it will be counted in all of it's labels\n",
    "# If an article has zero labels, it will be counted in 'no label'\n",
    "label_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-blame",
   "metadata": {},
   "source": [
    "* Annotated notebook showing your process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-parameter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
